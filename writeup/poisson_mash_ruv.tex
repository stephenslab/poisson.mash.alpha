\documentclass[onefignum,onetabnum,oneeqnum,final]{siamart190516}
\usepackage{amsfonts}
\usepackage{graphicx}
\setlength{\oddsidemargin}{0.65in}
\setlength{\evensidemargin}{0.65in}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{fullpage}
\usepackage{bm}
\usepackage{bbm}

\newsiamremark{remark}{Remark}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\linespread{1.25}


\title{Poisson Mash Model Allowing for Unwanted Variation}
\date{}

\begin{document}

\maketitle




\section{Model setup} \label{model}
Suppose there are $j=1, \dots, J$ genes and $i=1, \dots, N$ cells. The observed single cell count matrix $Y$ is $J \times N$, with its $(j, i)$ element $Y_{ji}$ denoting the count of gene $j$ in cell $i$.  

We assume that the $N$ cells come from $r=1, \dots, R$ conditions, with $n_r$ cells (indexed by $\mathcal{S}_r \subset \{1, \dots, N\}$) coming from condition $r$. Further assume that the $R$ conditions belong to $m=1, \dots, M$ subgroups ($1 \leq M < R$). For example, subgroups can be different cell types and conditions can be combinations of treatments and cell types. We are interested in comparing gene expression levels across conditions $r \in \mathcal{T}_m \subset \{1, \dots, R\}$ within each subgroup $m$, e.g., comparing gene expression levels corresponding to different treatments within each cell type. To do so, a first step is to collapse the single cell count matrix $Y$ into a condition level count matrix $X$, which is a $J \times R$ matrix with its $(j, r)$ element $X_{jr} = \sum_{i \in \mathcal{S}_r} Y_{ji}$.  

Let $s_i$ denote the size factor of cell $i$, which can be calculated by taking the sum (or equivalently, mean) of counts over all genes in cell $i$, or using other more robust methods \cite{bullard2010evaluation, lun2016pooling}.  Let $s_r = \sum_{i \in \mathcal{S}_r} s_i$ denote the size factor of condition $r$. 

We assume the following model for the matrix of counts $X$ collapsed over conditions: 
\begin{align}
X_{jr} \sim Pois (s_r \lambda_{jr}),  \label{eq:1} 
\end{align}
where $\lambda_{jr}$ denotes the gene-specific, condition-specific intensity parameter. For each gene $j$, we are interested in comparing $\lambda_{jr}$ across conditions $r \in \mathcal{T}_m$ within each subgroup $m$.   

To i) model possible correlations in $\lambda_{jr}$ across $r$, ii) allow over-dispersion in the count data, and iii) account for unwanted variation, for  condition $r$ which belongs to subgroup $m(r)$, we place the following prior on $\log(\lambda_{jr})$: 
\begin{align}
\log \left(\lambda_{jr} \right) = & \; \mu_{jm(r)} + \beta_{jr}  + \eta_{jr} + \sum_{d=1}^D \rho_{rd} f_{jd}, \label{eq:2} \\
\bm{\beta}_j \sim & \; \sum_{k,l} \pi_{kl} N(\bm{0}, w_l U_k)  \quad \text{where} \;\; \sum_{k,l} \pi_{kl} =1, \label{eq:3} \\  
\bm{\eta}_j \sim & \; N(\bm{0}, \psi_j^2 I_R). \label{eq:4}
\end{align}

In \eqref{eq:2},  $\mu_{jm(r)}$ represents the gene-specific, subgroup-specific underlying mean of $\log(\lambda_{jr})$,  and the term $\sum_{d=1}^D \rho_{rd} f_{jd}$ represents the bias caused by unwanted variation, with $F$ being a $J \times D$ matrix of unobserved factors and $\bm{\rho}$ being a $D \times R$ matrix of corresponding effects. Here we adopt a similar framework as in \cite{gerard2020empirical} to account for unwanted variation.  

In \eqref{eq:3}, $\bm{\beta}_j$ is an $R \times 1$ vector modeling the gene-specific, condition-specific effects which is our \textit{quantity of interest}, and has a mixture multivariate Gaussian prior involving a grid of scaling factors $w_l \: (l=1, \dots, L)$ and a set of covariance matrices $U_k \: (k=1, \dots, K)$ that include both canonical and data-driven ones.  $\bm{\pi} $ is a $KL \times 1$ vector of weights for different prior covariances.

In \eqref{eq:4}, $\bm{\eta}_j$ is an $R \times 1$ vector of Gaussian random effect with a gene-specific prior covariance $\psi_j^2 I_R$, which is introduced to allow for possible over-dispersion of single cell data.  


\section{Model fitting with variational approximation} \label{variational}
In \eqref{eq:1} to \eqref{eq:4}, only $X$ and $s_r \: (r=1, \dots, R)$ are observed, and the grid of scaling factors $w_l \: (l=1, \dots, L)$ can be chosen in a data-adaptive manner.  The remaining quantities need to be estimated. 

To fit the model described in Section \ref{model}, we first get an estimate $\hat{F}$ of $F$ by running factor analysis on the single cell count matrix $Y$ while accounting for condition-specific effects under a GLM model. This step can be performed using the R package ``glmpca" \cite{townes2019feature}.

With the plug-in estimate $\hat{F}$ for $F$, we now describe how to estimate the remaining quantities. Let $\bm{\Theta} \coloneqq \left( \bm{\mu}, \bm{\rho},  \bm{\pi}, \bm{U}, \bm{\psi}^2 \right)$ indicate the model parameters to be estimated from the data, where $\bm{\mu}$ is the $J \times M$ matrix of gene-specific, subgroup-specific mean parameters, $\bm{\psi}^2$ is the $J \times 1$ vector of gene-specific dispersion parameters, $\bm{\rho}$ is the $D \times R$ matrix of effects for unwanted variation, $\bm{\pi} $ is the $KL \times 1$ vector of prior weights, and $\bm{U}$ is the collection of prior covariance matrices. The data likelihood can be written as 
\begin{align}
L(\bm{\Theta}; \: X, \bm{s}, \hat{F})  =  & \; \prod_j \left[ \sum_{k, \: l} \pi_{kl} \; p\left(\bm{X}_j \mid \bm{\mu}_j, \bm{\rho}' \hat{\bm{f}}_j, w_l U_k, \psi_j^2  \right) \right] \label{eq:5} \\
= & \; \prod_j \left[ \sum_{k, \: l} \pi_{kl} \int p\left(\bm{X}_j \mid \bm{\mu}_j, \bm{\beta}_j, \bm{\eta}_j, \bm{\rho}' \hat{\bm{f}}_j \right) p\left(\bm{\beta}_j \mid w_l U_k \right) p\left(\bm{\eta}_j \mid \psi_j^2 \right) d \bm{\beta}_j \: d \bm{\eta}_j \right]. \label{eq:6}
\end{align}

As is commonly done when fitting mixture models, we introduce a $KL \times 1$ vector of latent indicator $\bm{z}_j$ for each gene $j$ to facilitate model fitting, such that $\sum_{k,l} z_{jkl} = 1$ and 
\begin{align}
\bm{\beta}_j \mid (z_{jkl} = 1) \; \sim  \; MVN(\bm{0},  \: w_l U_k).  \label{eq:7}
\end{align}

Let $\bm{Z}$ denote the collection of $\bm{z}_j$ for all $j$. With the introduction of latent indicator variables $\bm{z}_j$,  the complete data log-likelihood is
\begin{align}
\log L(\bm{\Theta}; \: X, \bm{s}, \hat{F},  \bm{Z}) = \sum_j \sum_{k, \: l} z_{jkl} \left[ \log \pi_{kl} + \log p\left(\bm{X}_j \mid \bm{\mu}_j,  \bm{\rho}' \hat{\bm{f}}_j, w_l U_k, \psi_j^2 \right) \right].  \label{eq:8} 
\end{align}

Let $\bm{\theta}_j \coloneqq \bm{\beta}_j + \bm{\eta}_j$ for each gene $j$, and $\bm{\theta}$ denote the collection of $\bm{\theta}_j$ for all $j$.  We are interested in the joint posterior of $(\bm{\theta}, \bm{Z})$ which does not have a closed-form:
\begin{align} \label{eq:9}
& \; p\left(\bm{\theta}, \bm{Z} \mid X, \bm{\mu}, \bm{\rho}, \bm{\pi}, \bm{U},  \bm{\psi}^2 \right) \propto p\left(X \mid \bm{\theta},  \bm{\mu}, \bm{\rho} \right) \: p\left(\bm{\theta}, \bm{Z} \mid  \bm{\pi}, \bm{U}, \bm{\psi}^2 \right)  \\
\propto & \; \prod_j \left\{ p\left(\bm{X}_j \mid \bm{\theta}_j, \bm{\mu}_j, \bm{\rho}' \hat{\bm{f}}_j \right) \:  \prod_{k, \: l} \left[\pi_{kl} \: N\left(\bm{\theta}_j \mid \bm{0}, w_l U_k + \psi_j^2 I_R \right) \right]^{z_{jkl}} \right\}. \nonumber
\end{align}

Therefore, we approximate the true joint posterior $p\left(\bm{\theta}_j, \bm{z}_j \mid \bm{X}_j, \bm{\mu}_j, \psi_j^2, \bm{\rho}, \bm{\pi}, \bm{U} \right)$ with $q(\bm{\theta}_j, \bm{z}_j)$, which is restricted to be a mixture of multivariate Gaussian distributions. That is,  for each $j$,
\begin{align} 
q(\bm{\theta}_j, \bm{z}_j) = q(\bm{\theta}_j \mid \bm{z}_j) \; q(\bm{z}_j) = \prod_{k, \: l}  \left[\zeta_{jkl} \: N(\bm{\theta}_j \mid \bm{\gamma}_{jkl}, V_{jkl}) \right]^{z_{jkl}}, \label{eq:10}
\end{align}
where $\bm{\zeta}_j$ is a $KL \times 1$ vector of posterior weights for $\bm{z}_j$. 


We estimate the model parameters $\bm{\mu}, \bm{\rho}, \bm{\pi}, \bm{U}, \bm{\psi}^2$ and the variational approximation parameters $\{\bm{\zeta}_j\}_j$,  $\{\bm{\gamma}_{jkl}\}_{j, k, l}$, $\{V_{jkl}\}_{j, k, l}$ by maximizing the ``overall" ELBO defined in \eqref{eq:11}:
\begin{align} \label{eq:11}
& \; F_{overall}\left(q(\bm{\theta}, \bm{Z}), \bm{\mu}, \bm{\rho}, \bm{\pi}, \bm{U}, \bm{\psi}^2;  X, \bm{s} \right) \\
 \coloneqq & \; \log p\left(X \mid \bm{\mu},  \bm{\rho}, \bm{\pi}, \bm{U},  \bm{\psi}^2 \right) - D_{KL} \left(q(\bm{\theta}, \bm{Z}) \; \lVert \;  p\left(\bm{\theta}, \bm{Z} \mid X, \bm{\mu}, \bm{\rho}, \bm{\pi}, \bm{U}, \bm{\psi}^2 \right) \right) \\
 = & \; \mathbb{E}_q \left[ \log p(X,  \bm{\theta}, \bm{Z} \mid  \bm{\mu}, \bm{\rho}, \bm{\pi}, \bm{U},  \bm{\psi}^2 ) \right] -  \mathbb{E}_q \left[ \log q(\bm{\theta},  \bm{Z}) \right]  \\
 = & \; \mathbb{E}_q \left[ \log p(X \mid \bm{\theta}, \bm{\mu}, \bm{\rho}) + \log p(\bm{\theta}, \bm{Z} \mid \bm{\pi}, \bm{\psi}^2, \bm{U}) \right] -  \mathbb{E}_q \left[ \log q(\bm{\theta}, \bm{Z}) \right]  \\
 = & \; \sum_j \sum_{k, \: l} \zeta_{jkl} \left[\log \pi_{kl} + F\left(\bm{\gamma}_{jkl},  V_{jkl}, \bm{\mu}_j, \bm{\rho}' \hat{\bm{f}}_j,  w_l U_k, \psi_j^2;  \bm{X}_j \right) - \log \zeta_{jkl} \right],
\end{align}
where $F\left(\bm{\gamma}_{jkl},  V_{jkl}, \bm{\mu}_j, \bm{\rho}' \hat{\bm{f}}_j, w_l U_k, \psi_j^2;  \bm{X}_j \right)$ is the ``local" ELBO defined in \eqref{eq:12}:
\begin{align} 
& \; F\left(\bm{\gamma}_{jkl},  V_{jkl},  \bm{\mu}_j, \bm{\rho}' \hat{\bm{f}}_j, w_l U_k, \psi_j^2;  \bm{X}_j \right) \label{eq:12} \\
\coloneqq & \; \mathbb{E}_{q_{jkl}} \left[ \log p(\bm{X}_j \mid \bm{\mu}_j, \bm{\theta}_j, \bm{\rho}' \hat{\bm{f}}_j) \right] - D_{KL}\left(N (\bm{\theta}_j \mid \bm{\gamma}_{jkl}, V_{jkl}) \; \lVert \; N(\bm{\theta}_j \mid \bm{0}, w_l U_k + \psi_j^2 I_R) \right)  \nonumber \\
=  & \sum_r \left\{X_{jr} \left(\log s_r + \mu_{jm(r)} + \sum_{d=1}^D \rho_{rd} \hat{f}_{jd} +  \gamma_{jklr} \right) - s_r \exp\left(\mu_{jm(r)} + \sum_{d=1}^D \rho_{rd} \hat{f}_{jd}  + \gamma_{jklr} +  \frac{1}{2} V_{jkl, rr} \right) - \log(X_{jr}!) \right\} \nonumber \\
& \; -  D_{KL}\left(N (\bm{\theta}_j \mid \bm{\gamma}_{jkl}, V_{jkl}) \; \lVert \; N(\bm{\theta}_j \mid \bm{0}, w_l U_k + \psi_j^2 I_R ) \right). \nonumber
\end{align}


\bigskip
\bigskip
\bigskip




\bibliographystyle{siamplain}
\bibliography{references}
\end{document}

